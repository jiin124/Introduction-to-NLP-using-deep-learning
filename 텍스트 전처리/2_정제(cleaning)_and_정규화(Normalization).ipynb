{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. 정제(cleaning) and 정규화(Normalization)",
      "provenance": [],
      "authorship_tag": "ABX9TyOx1teSbhIZQ9H4m8obErAE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiin124/Introduction-to-NLP-using-deep-learning/blob/main/%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EC%A0%84%EC%B2%98%EB%A6%AC/2_%EC%A0%95%EC%A0%9C(cleaning)_and_%EC%A0%95%EA%B7%9C%ED%99%94(Normalization).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰화 작업 전, 후에는 텍스트 데이터를 용도에 맞게 정제(cleaning) 및 정규화(normalization)하는 일이 항상 함께한다. 정제 및 정규화의 목적은 각각 다음과 같다. \n",
        "\n",
        "- **정제(cleaning)** : 갖고 있는 코퍼스로부터 노이즈 데이터를 제거.\n",
        "- **정규화(normalization)** : 표현방법이 다른 단어들을 통합시켜 같은 단어로 만들어준다. \n",
        "\n",
        "사실 완벽한 정제 작업은 어려워서 대부분의 경우 이정도면 됐다!! 하하!! 라며 합리화함. "
      ],
      "metadata": {
        "id": "42UKxI4HhVDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 규칙에 기반한 표기가 다른 단어들의 통합\n",
        "\n",
        "USA와 US는 같은 의미를 가지므로 하나의 단어로 정규화해볼 수 있다. 이런 정규화를 거치게 되면 US를 찾아도 USA도 함께 찾을 수 있을 것이다. \n",
        "표기가 다른 단어들을 통합하는 어간 추출(stemming)과 표제어 추출(lemmatization)에 대해서 더 자세히 알아보자. \n",
        "\n",
        "# 2. 대 , 소문자 통합\n",
        "\n",
        "대, 소문자를 통합하면 단어의 개수를 줄일 수있다. 영어권에서는 대문자는 주로 문자의 맨앞이나 특정상황에서만 쓰고 대부분 글은 소문자로 쓰기 때문에 대문자->소문자 변환작업을 해준다. \n",
        "\n",
        "물론 대문자와 소문자를 무작정 통합하면 안됨. 대문자와 소문자가 구분되어야 할 상황도 있기 때문이다. 미국을 뜻하는 US와 우리를 뜻하는 us는 구분되어야 한다. 또 회사 이름(General Motors)나 사람 이름 (Bush) 등은 대문자로 유지되는게 좋다. \n",
        "\n",
        "# 3. 불필요한 단어의 제거\n",
        "\n",
        "정제 작업에서 제거해야하는 노이즈 데이터는 자연어가 아니면서 아무 의미도 갖지 않는 글자들(특수문자등)을 의미하기도 하지만 분석하고자 하는 목적에 맞지 않은 불필요 단어들을 노이즈 데이터라고 하기도 한다. \n",
        "\n",
        "불필요 단어들을 제거하는 방법으로는** 불용어 제거**와 **등장빈도가 적은 단어, 길이가 짧은 단어들을 제거**하는 방법이 있다. 불용어 제거는 불용어 챕터에서 더욱 자세히 다루기로 하고, 여기서는 등장빈도가 적은 단어와 길이가 짧은 단어를 제거하는 경우에 대해서 간략히 다루자. \n",
        "\n",
        "## (1) 등장 빈도가 적은 단어\n",
        "\n",
        "예를 들어 입력된 메일이 정상 메일인지 스팸 메일인지 분류하는 스팸 메일 분류기를 설계한다고 가정해보겠다. 총 100000개의 메일을 가지고 정상 메일에서는 어떤 단어들이 주로 등장하고, 스팸 메일에서는 어떤 단어들이 주로 등장하는지를 가지고 설계하고자 한다. 이때 1000000개의 메일 데이터에서 총 합 5번밖에 등장하지 않은 단어가 있다면 이 단어는 직관적으로 분류에 거의 도움이 안되는 단어라는 걸 알 수 있다. \n",
        "\n",
        "## (2) 길이 짧은 단어\n",
        "\n",
        "영어권 언어에서는 길이가 짧은 단어를 삭제하는 것만으로도 자연어 처리에서 크게 의미가 없는 단어들을 제거하는 효과를 볼 수 있다고 알려져 있다. 즉 영어권언어에서는 길이가 짧은 단어들은 대부분 불용어에 해당된다. 하지만 한국어는 길이가 짧은 단어라고 삭제하는 이런 방법이 크게 유효하지 않을 수 있다. \n",
        "\n",
        "- 보통 영어단어 길이가 한국어 단어 길이보다 길다. \n",
        "\n",
        "영어는 길이가 2~3 이하인 단어를 제거하는 것만으로도 크게 의미를 갖지 못하는 단어를 줄이는 효과를 갖고 있다. 예를 들어 갖고 있는 텍스트 데이터에서 길이가 1인 단어를 제거하는 코드를 수행하면 대부분의 자연어 처리에서 의미를 갖지 못하는 단어인 관사 'a'와 주어로 쓰이는 'I'가 제거된다. 하지만 fox, dog,car 등 길이가 3인 명사들이 제거 되기 시작하므로 사용하고자 하는 데이터에서 해당 방법을 사용해도 되는지에 대한 고민이 필요하다. "
      ],
      "metadata": {
        "id": "SW6lG5Udh_mJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"I was wondering if anyone out there could enlighten me on this car.\"\n",
        "\n",
        "#길이가 1~2인 단어들을 정규 표현식을 사용해 삭제\n",
        "shortword=re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
        "print(shortword.sub('',text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAQF3b3uio8S",
        "outputId": "6899e06f-af71-4d57-8fb9-d4c94a318ec1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " was wondering anyone out there could enlighten this car.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RraQZfnIhO1E"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}