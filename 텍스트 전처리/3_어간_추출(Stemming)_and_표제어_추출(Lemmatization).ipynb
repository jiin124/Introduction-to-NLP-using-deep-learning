{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. 어간 추출(Stemming) and 표제어 추출(Lemmatization)",
      "provenance": [],
      "authorship_tag": "ABX9TyPTpJE04TOao+BS+Ibi2IMc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiin124/Introduction-to-NLP-using-deep-learning/blob/main/%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EC%A0%84%EC%B2%98%EB%A6%AC/3_%EC%96%B4%EA%B0%84_%EC%B6%94%EC%B6%9C(Stemming)_and_%ED%91%9C%EC%A0%9C%EC%96%B4_%EC%B6%94%EC%B6%9C(Lemmatization).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정규화 기법 중 코퍼스에 있는 단어의 개수를 줄일 수 있는 기법인** 표제어 추출**(lemmatization)과 **어간 추출**(stemming)의 개념에 대해서 알아보자. 또한 이 둘의 결과가 어떻게 다를까?\n",
        "\n",
        "이 두 작업이 갖고 있는 의미는 눈으로 봤을 때는 서로 다른 단어들이지만, 하나의 단어로 일반화시킬 수 있다면 하나의 단어로 일반화시켜서 문서 내의 단어 수를 줄이겠다는 것. 이러한 방법들은 단어의 빈도수를 기반으로 문제를 풀고자 하는 뒤에서 학습하게 될 BoW(Bag of Words) 표현을 사용하는 자연어 처리 문제에서 주로 사용된다. 자연어 처리에서 전처리, 더 정확히는 **정규화의 지향점은 언제나 갖고 있는 코퍼스로부터 복잡성을 줄이는 일입니다.**\n"
      ],
      "metadata": {
        "id": "mnLEq_t2nHCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 표제어 추출(Lemmatization)\n",
        "\n",
        "표제어(Lemma)는 한글로는 '표제어'또는 '기본 사전형 단어' 정도의 의미를 갖는다. 예를들어 am,are,is는 서로 다른 스펠링이지만 그 뿌리 단어는 be라고 볼 수 있다. 이때 이 단어들의 표제어는 be라고 한다. \n",
        "\n",
        "표제어 추출을 하는 가장 섬세한 방법은 단어의 형태소를 살펴보는 것. 형태소의 종류로 어간(stem)과 접사(affix)가 존재. \n",
        "\n",
        "#### 1) 어간(stem) : 단어의 의미를 담고 있는 단어의 핵심 부분\n",
        "\n",
        "#### 2) 접사(affix) : 단어에 추가적인 의미를 주는 부분. \n",
        "\n",
        "NLTK에서는 표제어 추출을 위한 도구인 `WordNetLemmatizer`를 지원한다. "
      ],
      "metadata": {
        "id": "58wV1Fmin_2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92qmNK53p1Nc",
        "outputId": "f3e4718d-2c74-4cc1-b737-d566767920da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gmeRsstnC0l",
        "outputId": "f3f4ba70-8f7d-4b4a-b651-455a210e57b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "표제어 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
            "표제어 추출 후 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "words=['policy','doing','organization','have','going','love','lives','fly','dies',\n",
        "       'watched','has','starting']\n",
        "\n",
        "print('표제어 추출 전 :',words)\n",
        "print('표제어 추출 후 :',[lemmatizer.lemmatize(word) for word in words])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lives같은 경우는 표제어가 잘 추출되었는데, dy나, ha 같이 알수없는 단어도 출력이 되었다. 이는 표제어 추출기(lemmatizer)가 본래 단어의 품사 정보를 알아야만 정확한 결과를 얻을 수 있기 때문이다. \n",
        "\n",
        "WordNetLemmatizer는 입력으로 단어가 동사 품사라는 사실을 알려줄 수 있다. 즉 dies와 watched, has가 문장에서 동사로 쓰였다는 것을 알려준다면 표제어 추출기는 품사의 정보를 보존하면서 정확한 Lemma를 출력하게 된다. "
      ],
      "metadata": {
        "id": "GWTl1XNmqtrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('dies','v')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "huiruRjlpwSM",
        "outputId": "71a1586f-084b-4507-cc57-cc9e3d2f6794"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'die'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('watched','v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qBSxf9QqrE7h",
        "outputId": "9199c13f-d965-41ff-f4c8-fce93e19d833"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'watch'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('has','v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NfNPfcfArI3L",
        "outputId": "b5d89b62-d0dc-41db-c425-b22321cc8171"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'have'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 어간 추출(Stemming)\n",
        "\n",
        "어간(stem)을 추출하는 작업을 어간 추출(stemming)이라고 한다. 섬세한 작업은 아니라서 어간 추출 후 나오는 단어는 사전에 존재하지 않는 단어일 수도 있음. \n",
        "\n",
        "어간 추출 알고리즘 중 하나인 포터 알고리즘(Porter Algorithm)에 아래 문장을 넣어보자.\n",
        "\n",
        "**This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.**"
      ],
      "metadata": {
        "id": "LSVjxxgXrNWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBubCbo5saet",
        "outputId": "362ee178-a15c-45d1-cca4-ec7b8b068653"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stemmer=PorterStemmer()\n",
        "\n",
        "sentence=\"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\"\n",
        "\n",
        "tokenized_sentence=word_tokenize(sentence)\n",
        "\n",
        "print('어간 추출 전 :', tokenized_sentence)\n",
        "print('어간 추출 후: ',[stemmer.stem(word) for word in tokenized_sentence])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5ZjfOOHrKRl",
        "outputId": "9bbe7cb1-18e7-462b-f874-3cf1f577023a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어간 추출 전 : ['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n",
            "어간 추출 후:  ['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words=['formalize','allowance','electricical']\n",
        "\n",
        "print('어간 추출 전:',words)\n",
        "print('어간 추출 후:',[stemmer.stem(word) for word in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPOVDTcusZHM",
        "outputId": "5842cbfa-a285-492a-be2c-fd1b2e5688a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어간 추출 전: ['formalize', 'allowance', 'electricical']\n",
            "어간 추출 후: ['formal', 'allow', 'electric']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "※ Porter 알고리즘의 상세 규칙은 마틴 포터의 홈페이지에서 확인할 수 있다.\n",
        "\n",
        "어간 추출 속도는 표제어 추출보다 일반적으로 빠른데. 포터 어간 추출기는 정밀하게 설계되어 정확도가 높으므로 영어 자연어 처리에서 어간 추출을 하고자 한다면 가장 준수한 선택이다. NLTK에서는 포터알고리즘외에도 랭커스터 스태머 알고리즘을 지원한다. "
      ],
      "metadata": {
        "id": "KBoS7l0eta15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "porter_stemmer=PorterStemmer()\n",
        "lancaster_stemmer=LancasterStemmer()\n",
        "\n",
        "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "\n",
        "print('어간 추출 전 :',words)\n",
        "print('포터 스태머의 어간 추출 후: ',[porter_stemmer.stem(w) for w in words])\n",
        "print('랭커스터 스테머의 어간 추출 후:',[lancaster_stemmer.stem(w) for w in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DQb2EfFs5b7",
        "outputId": "b1074bc9-ec0b-41f2-f6c4-7912f07c6325"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어간 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
            "포터 스태머의 어간 추출 후:  ['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start']\n",
            "랭커스터 스테머의 어간 추출 후: ['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "동일한 단어들의 나열에 대해서 두 스태머는 전혀 다른 결과를 보여줍니다. 두 스태머 알고리즘은 서로 다른 알고리즘을 사용하기 때문입니다. 그렇기 때문에 이미 알려진 알고리즘을 사용할 때는, 사용하고자 하는 코퍼스에 스태머를 적용해보고 어떤 스태머가 해당 코퍼스에 적합한지를 판단한 후에 사용하여야 합니다.\n",
        "\n",
        "동일한 단어에 대해 표제어 추출과 어간추출을 각각 수행했을 때 결과 차이 보기\n",
        "\n",
        "< Stemming >\n",
        "- am → am\n",
        "- the going → the go\n",
        "- having → hav\n",
        "\n",
        "< Lemmatization >\n",
        "- am → be\n",
        "- the going → the going\n",
        "- having → have"
      ],
      "metadata": {
        "id": "SumSggFp-ERe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "uRV3eKi8_LHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d1vpZNGf97v_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}