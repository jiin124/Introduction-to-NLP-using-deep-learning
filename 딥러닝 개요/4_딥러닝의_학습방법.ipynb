{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_딥러닝의 학습방법",
      "provenance": [],
      "authorship_tag": "ABX9TyM2uWuLpevGJu/6LRtbXAc2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "딥러닝의 학습 방법의 이해를 위해 필요한 개념인 손실함수, 옵티마이저, 에포크의 개념을 정리. "
      ],
      "metadata": {
        "id": "3_3-IkvLmagr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 손실함수(Loss function)\n",
        "\n",
        "손실 함수는 실제값과 예측값의 차이를 수치화해주는 함수입니다. 이 두 값의 차이. 즉, 오차가 클 수록 손실 함수의 값은 크고 오차가 작을 수록 손실 함수의 값은 작아집니다.\n",
        "\n",
        "- 회귀 : 평균 제곱 오차\n",
        "- 분류 : 크로스 엔트로피\n",
        "\n",
        "손실함수의 값을 최소화하는 두개의 매개변수인 가중치 w와 편향 b의 값을 찾는 것이 딥러닝의 학습 과정이므로 손실함수의 선정은 매우 중요. \n",
        "\n",
        "## 1) MSE(Mean Squared Error, MSE)\n",
        "\n",
        "평균제곱오차. 연속형 변수를 예측할 때 사용. \n",
        "다음과 같이 compile의 loss에 문자열 'mse'라고 기재해 사용가능."
      ],
      "metadata": {
        "id": "CRQeXf6zmgJp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhrLt1DilQ11"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='mse',metrics=['mse'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래와 같이사용 가능"
      ],
      "metadata": {
        "id": "jWmWDFTxmgLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError(), metrics=['mse'])"
      ],
      "metadata": {
        "id": "aRHYbHrKnu3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥러닝 자연어 처리는 대부분 분류 문제이므로 평균 제곱 오차보다는 아래의 **크로스 엔트로피** 함수들을 주로 사용"
      ],
      "metadata": {
        "id": "6KJBj_ndnv2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 이진 크로스 엔트로피(Binary Cross-Entropy)\n",
        "\n",
        "이항 교차 엔트로피라고도 부르는 손실함수이다. 출력층에서 시그모이드함수를 사용하는 **이진 분류**의 경우 binary_crossentropy를 사용한다. "
      ],
      "metadata": {
        "id": "xCq8a7kkn6BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])"
      ],
      "metadata": {
        "id": "cxFCRL3rn1nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer='adam', metrics=['acc'])"
      ],
      "metadata": {
        "id": "YlNGKfTBorQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) 카테고리칼 크로스 엔트로피(Categorical Cross-entropy)\n",
        "\n",
        "범주형 교차 엔트로피라고도 불리는 손실함수. 출력층에서 소프트맥스 함수를 사용하는 다중 클래스 분류일 경우 사용한다. "
      ],
      "metadata": {
        "id": "E5uJnDmgorxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])"
      ],
      "metadata": {
        "id": "4YxTcqWNpXgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer='adam', metrics=['acc'])"
      ],
      "metadata": {
        "id": "hPBGMyw8phgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약 레이블에 대해서 원-핫인코딩을 생략하고 정수값을 가진 레이블에 대해서 다중 클래스 분류를 수행하고 싶다면 'sparse_categorical_crossentropy'를 사용. "
      ],
      "metadata": {
        "id": "_LEFnrZ1piRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['acc'])"
      ],
      "metadata": {
        "id": "ZouFc1qTphi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer='adam', metrics=['acc'])"
      ],
      "metadata": {
        "id": "xuFtL5OIp_V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) 그 외에 다양한 손실 함수들\n",
        "아래의 텐서플로우 공식 문서 링크에서 방금 언급하지 않은 손실 함수 외에도 다양한 손실 함수들을 확인할 수 있습니다.\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
        "\n",
        "지금까지 자주 사용하는 손실 함수 몇 가지에 대해서 정리해봤습니다. 위 compile 코드에서 optimizer='adam' 이라는 부분에 주목해봅시다. 이는 아담이라는 옵티마이저를 사용했다라는 의미입니다. 손실 함수의 선정만큼이나 옵티마이저의 선정 또한 중요합니다. 이어서 옵티마이저에 대해서 정리해봅시다."
      ],
      "metadata": {
        "id": "c20KW7SwqHOI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 배치 크기(Batch Size)에 따른 경사 하강법\n",
        "\n",
        "손실함수의 값을 줄여나가며 학습하는 방법은 어떤 옵티마이저를 사용하느냐에 따라 달라진다. 여기서 배치(batch)는 가중치 등의 매개변수의 값을 조정하기 위해 사용하는 데이터의 양을 말한다. \n",
        "전체 데이터를 가지고 매개변수의 값을 조정할 수도 있고, 정해준 양의 데이터만 가지고도 매개변수의 값을 조정할 수 있다. \n",
        "\n",
        "## 1) 배치 경사 하강법(Batch Gradient Descent)\n",
        "\n",
        "- 가장 기본적인 경사하강법\n",
        "- 오차를 구할 떄 전체 데이터를 고려.\n",
        "- 딥러닝에서는 전체 데이터에 대한 한번의 훈련횟수를 1 에포크라고 하는데 배치 경사 하강법은 한번에 에포크에 모든 매개변수 업데이트를 단 한번 수행.\n",
        "- 한번의 매개변수 업데이트에 시간이 오래 걸림.\n",
        "- 메모리를 크게 요구. "
      ],
      "metadata": {
        "id": "BYR_Bkolq9ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,batch_size=len(X_train))"
      ],
      "metadata": {
        "id": "VxLQer1KsASg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 배치 크기가 1인 확률적 경사 하강법(Stochastic Gradient Descent,SGD)\n",
        "\n",
        "배치 경사 하강법은 시간이 너무 오래걸림. 배치 크기가 1인 확률적 경사 하강법은 매개변수 값을 조정 시 전체 데이터가 아니라 랜덤으로 선택한 하나의 데이터에 대해서만 계산"
      ],
      "metadata": {
        "id": "MvCH3pmor_3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=1)"
      ],
      "metadata": {
        "id": "ZvaAjodksV68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) 미니 배치 경사 하강법(Mini-Batch Gradient Descent)\n",
        "\n",
        "배치 크기를 지정하여 해당 데이터 개수만큼에 대해 계산해 매개변수의 값을 조정하는 경사하강법.\n",
        "\n",
        "빠르고, SGD보다 안정적. \n",
        "배치 크기는 일반적으로 2의 n제곱에 해당하는 숫자로 선택하는 것이 보편적. 별도로 지정해주지 않으면 2의 5제곱에 해당하는 숫자로 설정. "
      ],
      "metadata": {
        "id": "nbLOrV1Cq9wJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=128)"
      ],
      "metadata": {
        "id": "ga5_62KXs1ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 옵티마이저(optimizer)\n",
        "\n",
        "## 1) 모멘텀(Momentum)\n",
        "\n",
        "물리학 법칙. 모멘텀 경사 하강법에 관성을 더해줌. 모멘텀은 경사 하강법에서 계산된 접선의 기울기에 한 시점 전의 접선의 기울기값을 일정한 비율만큼 반영합니다. 이렇게 하면 마치 언덕에서 공이 내려올 때, 중간에 작은 웅덩이에 빠지더라도 관성의 힘으로 넘어서는 효과를 줄 수 있습니다.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "전체 함수에 걸쳐 최소값을 글로벌 미니멈(Global Minimum) 이라고 하고, 글로벌 미니멈이 아닌 특정 구역에서의 최소값인 로컬 미니멈(Local Minimum) 이라고 합니다. 로컬 미니멈에 도달하였을 때 글로벌 미니멈으로 잘못 인식하여 탈출하지 못하였을 상황에서 모멘텀. 즉, 관성의 힘을 빌리면 값이 조절되면서 현재의 로컬 미니멈에서 탈출하고 글로벌 미니멈 내지는 더 낮은 로컬 미니멈으로 갈 수 있는 효과를 얻을 수도 있습니다."
      ],
      "metadata": {
        "id": "C32eJAtvq9yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "0MQdg6dPqIM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 아다그라드(Adagrad)\n",
        "\n",
        "모든 매개변수에 동일한 학습률(learning rate)을 적용하는 것은 비효율적입니다. 아다그라드는 각 매개변수에 서로 다른 학습률을 적용시킵니다. 이때 변화가 많은 매개변수는 학습률이 작게 설정되고 변화가 적은 매개변수는 학습률을 높게 설정시킵니다."
      ],
      "metadata": {
        "id": "16_cMUbMuvXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.optimizers.Adagrad(lr=0.01,epsilon=1e-6)"
      ],
      "metadata": {
        "id": "_BtgkFn0vFsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) RMSprop\n",
        "\n",
        "Adagrad는 학습을 계속 진행한 경우에는 나중에 가서는 학습률이 지나치게 떨어진다는 단점이 있다. 이를 다른 수식으로 대체해 단점을 개선했다. "
      ],
      "metadata": {
        "id": "NxzM39g3vL0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.optimizers.RMSprop(lr=0.001,rho=0.9,epsilon=1e-06)"
      ],
      "metadata": {
        "id": "wnb25BHbvmFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) 아담(Adam)\n",
        "\n",
        "RMSprop와 모멘텀 두가지를 합친 방법. 방향과 학습률 두가지를 모두 잡음. "
      ],
      "metadata": {
        "id": "QDyqOOTXvwoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "metadata": {
        "id": "ix60GOpwv7ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) 사용 방법\n",
        "\n",
        "옵티마이저 인스턴스는 compile의 optimizer에서 호출한다. "
      ],
      "metadata": {
        "id": "7c7kKJpswX7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adam = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc'])"
      ],
      "metadata": {
        "id": "1pku_FITwddh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#걍 단순히 문자열로 'adam'으로 작성해도 동작함. 다른것들도 마찬가지\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "metadata": {
        "id": "3U4KIQurxCEK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}