{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_RNN을 이용한 텍스트 생성(Text Generation using RNN)",
      "provenance": [],
      "authorship_tag": "ABX9TyPRZMfGaCvfmnCL+K550BGb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiin124/Introduction-to-NLP-using-deep-learning/blob/main/%EC%88%9C%ED%99%98%EC%8B%A0%EA%B2%BD%EB%A7%9D/6_RNN%EC%9D%84_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%85%8D%EC%8A%A4%ED%8A%B8_%EC%83%9D%EC%84%B1(Text_Generation_using_RNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. RNN을 이용해 텍스트 생성하기\n",
        "\n",
        "예를 들어서 '경마장에 있는 말이 뛰고 있다'와 '그의 말이 법이다'와 '가는 말이 고와야 오는 말이 곱다'라는 세 가지 문장이 있다고 해봅시다. 모델이 문맥을 학습할 수 있도록 전체 문장의 앞의 단어들을 전부 고려하여 학습하도록 데이터를 재구성한다면 아래와 같이 총 11개의 샘플이 구성됩니다.\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "OfQE2I60i4T6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cZoAH2_Ri22t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
        "그의 말이 법이다\\n\n",
        "가는 말이 고와야 오는 말이 곱다\\n\"\"\""
      ],
      "metadata": {
        "id": "Y7uVqkXjjRJs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "단어집합 생성, 정수 인덱스"
      ],
      "metadata": {
        "id": "_CM1c6j2kPX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "vocab_size=len(tokenizer.word_index)+1#패딩을 위한 0을 고려해 +1해주기\n",
        "print('단어집합의 크기 : %d'%vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRlF5IBmjTUi",
        "outputId": "49c55e38-6313-4df3-a82b-df6cc286f77c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어집합의 크기 : 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_xpb6NAjjxZ",
        "outputId": "b320df1f-ad1b-462e-87ad-21493b449267"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련데이터 만들기\n",
        "\n",
        "sequences=list()\n",
        "\n",
        "for line in text.split('\\n'):\n",
        "  encoded=tokenizer.texts_to_sequences([line])[0]\n",
        "  #텍스트 안의 단어들을 숫자의 시퀀스의 형태로 변환합니다.\n",
        "  for i in range(1,len(encoded)):\n",
        "    sequence=encoded[:i+1]\n",
        "    sequences.append(sequence)\n",
        "\n",
        "print('학습에 사용할 샘플의 개수 : %d'%len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POetbUBijuda",
        "outputId": "2bf78c92-afa8-45b9-e0fb-c6485538f37d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습에 사용할 샘플의 개수 : 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omUQ3MjekC3Y",
        "outputId": "e8025415-e407-44a5-bd1b-ea5d5ab51de1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "우선 전체 샘플에 대해서 길이를 일치시켜 줍니다. 가장 긴 샘플의 길이를 기준으로 합니다. 현재 육안으로 봤을 때, 길이가 가장 긴 샘플은 [8, 1, 9, 10, 1, 11]이고 길이는 6입니다. 이를 코드로는 다음과 같이 구할 수 있습니다."
      ],
      "metadata": {
        "id": "zyHz1lJQmBRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=max(len(l) for l in sequences)\n",
        "print('샘플의 최대 길이 :{}'.format(max_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ee5gRsll2wK",
        "outputId": "226ae044-6446-4161-a2d1-4788e3d88aa7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 :6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#전체 샘플의 길이를 6으로 패딩\n",
        "sequences=pad_sequences(sequences,maxlen=max_len,padding='pre')"
      ],
      "metadata": {
        "id": "hIgkK10vmJQF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pad_sequences()는 모든 샘플에 대해서 0을 사용하여 길이를 맞춰줍니다. maxlen의 값으로 6을 주면 모든 샘플의 길이를 6으로 맞춰주며, padding의 인자로 'pre'를 주면 길이가 6보다 짧은 샘플의 앞에 0으로 채웁니다. 전체 훈련 데이터를 출력해봅니다."
      ],
      "metadata": {
        "id": "qJNX5Y-empET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcCS-1pzmng-",
        "outputId": "9069c029-522a-492e-92b5-e788c39a6835"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  2  3]\n",
            " [ 0  0  0  2  3  1]\n",
            " [ 0  0  2  3  1  4]\n",
            " [ 0  2  3  1  4  5]\n",
            " [ 0  0  0  0  6  1]\n",
            " [ 0  0  0  6  1  7]\n",
            " [ 0  0  0  0  8  1]\n",
            " [ 0  0  0  8  1  9]\n",
            " [ 0  0  8  1  9 10]\n",
            " [ 0  8  1  9 10  1]\n",
            " [ 8  1  9 10  1 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 샘플의 마지막 단어를 레이블로 분리, 레이블의 분리는 Numpy를 이용해 가능하다. 리스트의 마지막값을 제외하고 저장한 것은 x,리스트의 마지막 값 만 저장한 것은 y,이는 레이블에 해당된다. "
      ],
      "metadata": {
        "id": "tKeRo4kfon4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences=np.array(sequences)\n",
        "X=sequences[:,:-1]\n",
        "y=sequences[:,-1]"
      ],
      "metadata": {
        "id": "xnGiaARInOTa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcOOo50fovu8",
        "outputId": "4effcf98-7d08-4bf8-a019-016b1cc87c62"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  2]\n",
            " [ 0  0  0  2  3]\n",
            " [ 0  0  2  3  1]\n",
            " [ 0  2  3  1  4]\n",
            " [ 0  0  0  0  6]\n",
            " [ 0  0  0  6  1]\n",
            " [ 0  0  0  0  8]\n",
            " [ 0  0  0  8  1]\n",
            " [ 0  0  8  1  9]\n",
            " [ 0  8  1  9 10]\n",
            " [ 8  1  9 10  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww6lISz4pHWO",
        "outputId": "fea58f9e-ead6-4970-de98-8da6909a6a3e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN 모델에 훈련 데이터를 훈련시키기 전에 레이블에 대해서 원핫 인코딩을 수행"
      ],
      "metadata": {
        "id": "yO-xltjBpKW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y=to_categorical(y,num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "lfa6Jz3jpI1u"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFphW_okpRIu",
        "outputId": "f6ab4e31-5e6b-45b3-c293-1c33075cf4fb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 모델 설계하기"
      ],
      "metadata": {
        "id": "cdAvMxzJpWT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,Dense,SimpleRNN"
      ],
      "metadata": {
        "id": "zAw3rydNpVDo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼파라미터인 임베딩 벡터의 차원은 10, 은닉상태의 크기는 32이다. 다 대 일 구조의 RNN을 사용한다. 전결합층을 출력층으로 단어 집합 크기만큼의 뉴런을 배치하여 모델을 설계한다. 해당 모델은 마지막 시점에서 모든 가능한 단어 중 하나의 단어를 예측하는 다중 클래스 분류 문제를 수행하는 모델이다. 다중 클래스 분류 문제의 경우 출력층에 소프트 맥스 회귀를 사용해야하므로 활성화 함수로는 소프트 맥스 함수를 사용하고, 손실함수로 크로스 엔트로피함수를 사용해 200에포크를 수행한다. "
      ],
      "metadata": {
        "id": "ZNtwxVsnpx_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim=10\n",
        "hidden_units=32\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,embedding_dim))\n",
        "model.add(SimpleRNN(hidden_units))\n",
        "model.add(Dense(vocab_size,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X,y,epochs=200,verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JWT0h1Kpdfr",
        "outputId": "e6baa3a8-30ea-44a7-de7a-706ec09c43b9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 - 1s - loss: 2.4662 - accuracy: 0.0000e+00 - 1s/epoch - 1s/step\n",
            "Epoch 2/200\n",
            "1/1 - 0s - loss: 2.4509 - accuracy: 0.1818 - 4ms/epoch - 4ms/step\n",
            "Epoch 3/200\n",
            "1/1 - 0s - loss: 2.4357 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
            "Epoch 4/200\n",
            "1/1 - 0s - loss: 2.4204 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
            "Epoch 5/200\n",
            "1/1 - 0s - loss: 2.4049 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 6/200\n",
            "1/1 - 0s - loss: 2.3891 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
            "Epoch 7/200\n",
            "1/1 - 0s - loss: 2.3728 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
            "Epoch 8/200\n",
            "1/1 - 0s - loss: 2.3559 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
            "Epoch 9/200\n",
            "1/1 - 0s - loss: 2.3385 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
            "Epoch 10/200\n",
            "1/1 - 0s - loss: 2.3203 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
            "Epoch 11/200\n",
            "1/1 - 0s - loss: 2.3013 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
            "Epoch 12/200\n",
            "1/1 - 0s - loss: 2.2814 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
            "Epoch 13/200\n",
            "1/1 - 0s - loss: 2.2607 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
            "Epoch 14/200\n",
            "1/1 - 0s - loss: 2.2390 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
            "Epoch 15/200\n",
            "1/1 - 0s - loss: 2.2164 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
            "Epoch 16/200\n",
            "1/1 - 0s - loss: 2.1929 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
            "Epoch 17/200\n",
            "1/1 - 0s - loss: 2.1684 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
            "Epoch 18/200\n",
            "1/1 - 0s - loss: 2.1431 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
            "Epoch 19/200\n",
            "1/1 - 0s - loss: 2.1170 - accuracy: 0.4545 - 5ms/epoch - 5ms/step\n",
            "Epoch 20/200\n",
            "1/1 - 0s - loss: 2.0904 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
            "Epoch 21/200\n",
            "1/1 - 0s - loss: 2.0634 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
            "Epoch 22/200\n",
            "1/1 - 0s - loss: 2.0362 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "1/1 - 0s - loss: 2.0091 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
            "Epoch 24/200\n",
            "1/1 - 0s - loss: 1.9824 - accuracy: 0.4545 - 10ms/epoch - 10ms/step\n",
            "Epoch 25/200\n",
            "1/1 - 0s - loss: 1.9566 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 26/200\n",
            "1/1 - 0s - loss: 1.9319 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 27/200\n",
            "1/1 - 0s - loss: 1.9087 - accuracy: 0.3636 - 9ms/epoch - 9ms/step\n",
            "Epoch 28/200\n",
            "1/1 - 0s - loss: 1.8873 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 29/200\n",
            "1/1 - 0s - loss: 1.8678 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
            "Epoch 30/200\n",
            "1/1 - 0s - loss: 1.8502 - accuracy: 0.3636 - 7ms/epoch - 7ms/step\n",
            "Epoch 31/200\n",
            "1/1 - 0s - loss: 1.8344 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
            "Epoch 32/200\n",
            "1/1 - 0s - loss: 1.8198 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
            "Epoch 33/200\n",
            "1/1 - 0s - loss: 1.8061 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
            "Epoch 34/200\n",
            "1/1 - 0s - loss: 1.7926 - accuracy: 0.3636 - 6ms/epoch - 6ms/step\n",
            "Epoch 35/200\n",
            "1/1 - 0s - loss: 1.7788 - accuracy: 0.3636 - 5ms/epoch - 5ms/step\n",
            "Epoch 36/200\n",
            "1/1 - 0s - loss: 1.7642 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
            "Epoch 37/200\n",
            "1/1 - 0s - loss: 1.7486 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
            "Epoch 38/200\n",
            "1/1 - 0s - loss: 1.7318 - accuracy: 0.4545 - 4ms/epoch - 4ms/step\n",
            "Epoch 39/200\n",
            "1/1 - 0s - loss: 1.7140 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
            "Epoch 40/200\n",
            "1/1 - 0s - loss: 1.6953 - accuracy: 0.4545 - 10ms/epoch - 10ms/step\n",
            "Epoch 41/200\n",
            "1/1 - 0s - loss: 1.6759 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
            "Epoch 42/200\n",
            "1/1 - 0s - loss: 1.6561 - accuracy: 0.4545 - 10ms/epoch - 10ms/step\n",
            "Epoch 43/200\n",
            "1/1 - 0s - loss: 1.6360 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n",
            "Epoch 44/200\n",
            "1/1 - 0s - loss: 1.6159 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
            "Epoch 45/200\n",
            "1/1 - 0s - loss: 1.5959 - accuracy: 0.4545 - 8ms/epoch - 8ms/step\n",
            "Epoch 46/200\n",
            "1/1 - 0s - loss: 1.5759 - accuracy: 0.4545 - 13ms/epoch - 13ms/step\n",
            "Epoch 47/200\n",
            "1/1 - 0s - loss: 1.5560 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
            "Epoch 48/200\n",
            "1/1 - 0s - loss: 1.5362 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
            "Epoch 49/200\n",
            "1/1 - 0s - loss: 1.5163 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
            "Epoch 50/200\n",
            "1/1 - 0s - loss: 1.4963 - accuracy: 0.4545 - 7ms/epoch - 7ms/step\n",
            "Epoch 51/200\n",
            "1/1 - 0s - loss: 1.4760 - accuracy: 0.4545 - 6ms/epoch - 6ms/step\n",
            "Epoch 52/200\n",
            "1/1 - 0s - loss: 1.4556 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n",
            "Epoch 53/200\n",
            "1/1 - 0s - loss: 1.4349 - accuracy: 0.5455 - 6ms/epoch - 6ms/step\n",
            "Epoch 54/200\n",
            "1/1 - 0s - loss: 1.4140 - accuracy: 0.5455 - 8ms/epoch - 8ms/step\n",
            "Epoch 55/200\n",
            "1/1 - 0s - loss: 1.3930 - accuracy: 0.5455 - 11ms/epoch - 11ms/step\n",
            "Epoch 56/200\n",
            "1/1 - 0s - loss: 1.3719 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 57/200\n",
            "1/1 - 0s - loss: 1.3508 - accuracy: 0.5455 - 7ms/epoch - 7ms/step\n",
            "Epoch 58/200\n",
            "1/1 - 0s - loss: 1.3299 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 59/200\n",
            "1/1 - 0s - loss: 1.3091 - accuracy: 0.5455 - 10ms/epoch - 10ms/step\n",
            "Epoch 60/200\n",
            "1/1 - 0s - loss: 1.2887 - accuracy: 0.5455 - 10ms/epoch - 10ms/step\n",
            "Epoch 61/200\n",
            "1/1 - 0s - loss: 1.2685 - accuracy: 0.5455 - 9ms/epoch - 9ms/step\n",
            "Epoch 62/200\n",
            "1/1 - 0s - loss: 1.2488 - accuracy: 0.5455 - 5ms/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "1/1 - 0s - loss: 1.2293 - accuracy: 0.6364 - 11ms/epoch - 11ms/step\n",
            "Epoch 64/200\n",
            "1/1 - 0s - loss: 1.2103 - accuracy: 0.6364 - 5ms/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "1/1 - 0s - loss: 1.1916 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n",
            "Epoch 66/200\n",
            "1/1 - 0s - loss: 1.1732 - accuracy: 0.6364 - 6ms/epoch - 6ms/step\n",
            "Epoch 67/200\n",
            "1/1 - 0s - loss: 1.1552 - accuracy: 0.6364 - 5ms/epoch - 5ms/step\n",
            "Epoch 68/200\n",
            "1/1 - 0s - loss: 1.1375 - accuracy: 0.6364 - 7ms/epoch - 7ms/step\n",
            "Epoch 69/200\n",
            "1/1 - 0s - loss: 1.1200 - accuracy: 0.6364 - 9ms/epoch - 9ms/step\n",
            "Epoch 70/200\n",
            "1/1 - 0s - loss: 1.1029 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n",
            "Epoch 71/200\n",
            "1/1 - 0s - loss: 1.0861 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n",
            "Epoch 72/200\n",
            "1/1 - 0s - loss: 1.0696 - accuracy: 0.7273 - 7ms/epoch - 7ms/step\n",
            "Epoch 73/200\n",
            "1/1 - 0s - loss: 1.0534 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 74/200\n",
            "1/1 - 0s - loss: 1.0375 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 75/200\n",
            "1/1 - 0s - loss: 1.0219 - accuracy: 0.7273 - 7ms/epoch - 7ms/step\n",
            "Epoch 76/200\n",
            "1/1 - 0s - loss: 1.0066 - accuracy: 0.7273 - 7ms/epoch - 7ms/step\n",
            "Epoch 77/200\n",
            "1/1 - 0s - loss: 0.9914 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 78/200\n",
            "1/1 - 0s - loss: 0.9765 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
            "Epoch 79/200\n",
            "1/1 - 0s - loss: 0.9618 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n",
            "Epoch 80/200\n",
            "1/1 - 0s - loss: 0.9473 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 81/200\n",
            "1/1 - 0s - loss: 0.9331 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
            "Epoch 82/200\n",
            "1/1 - 0s - loss: 0.9190 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n",
            "Epoch 83/200\n",
            "1/1 - 0s - loss: 0.9052 - accuracy: 0.7273 - 7ms/epoch - 7ms/step\n",
            "Epoch 84/200\n",
            "1/1 - 0s - loss: 0.8917 - accuracy: 0.7273 - 12ms/epoch - 12ms/step\n",
            "Epoch 85/200\n",
            "1/1 - 0s - loss: 0.8783 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
            "Epoch 86/200\n",
            "1/1 - 0s - loss: 0.8652 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 87/200\n",
            "1/1 - 0s - loss: 0.8523 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n",
            "Epoch 88/200\n",
            "1/1 - 0s - loss: 0.8396 - accuracy: 0.7273 - 15ms/epoch - 15ms/step\n",
            "Epoch 89/200\n",
            "1/1 - 0s - loss: 0.8271 - accuracy: 0.7273 - 10ms/epoch - 10ms/step\n",
            "Epoch 90/200\n",
            "1/1 - 0s - loss: 0.8149 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
            "Epoch 91/200\n",
            "1/1 - 0s - loss: 0.8028 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 92/200\n",
            "1/1 - 0s - loss: 0.7909 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 93/200\n",
            "1/1 - 0s - loss: 0.7792 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n",
            "Epoch 94/200\n",
            "1/1 - 0s - loss: 0.7677 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 95/200\n",
            "1/1 - 0s - loss: 0.7564 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 96/200\n",
            "1/1 - 0s - loss: 0.7453 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 97/200\n",
            "1/1 - 0s - loss: 0.7343 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 98/200\n",
            "1/1 - 0s - loss: 0.7235 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
            "Epoch 99/200\n",
            "1/1 - 0s - loss: 0.7129 - accuracy: 0.7273 - 8ms/epoch - 8ms/step\n",
            "Epoch 100/200\n",
            "1/1 - 0s - loss: 0.7024 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
            "Epoch 101/200\n",
            "1/1 - 0s - loss: 0.6920 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
            "Epoch 102/200\n",
            "1/1 - 0s - loss: 0.6818 - accuracy: 0.7273 - 6ms/epoch - 6ms/step\n",
            "Epoch 103/200\n",
            "1/1 - 0s - loss: 0.6718 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
            "Epoch 104/200\n",
            "1/1 - 0s - loss: 0.6619 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
            "Epoch 105/200\n",
            "1/1 - 0s - loss: 0.6521 - accuracy: 0.7273 - 7ms/epoch - 7ms/step\n",
            "Epoch 106/200\n",
            "1/1 - 0s - loss: 0.6424 - accuracy: 0.7273 - 5ms/epoch - 5ms/step\n",
            "Epoch 107/200\n",
            "1/1 - 0s - loss: 0.6329 - accuracy: 0.7273 - 7ms/epoch - 7ms/step\n",
            "Epoch 108/200\n",
            "1/1 - 0s - loss: 0.6235 - accuracy: 0.8182 - 9ms/epoch - 9ms/step\n",
            "Epoch 109/200\n",
            "1/1 - 0s - loss: 0.6142 - accuracy: 0.8182 - 9ms/epoch - 9ms/step\n",
            "Epoch 110/200\n",
            "1/1 - 0s - loss: 0.6050 - accuracy: 0.8182 - 8ms/epoch - 8ms/step\n",
            "Epoch 111/200\n",
            "1/1 - 0s - loss: 0.5959 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
            "Epoch 112/200\n",
            "1/1 - 0s - loss: 0.5869 - accuracy: 0.8182 - 7ms/epoch - 7ms/step\n",
            "Epoch 113/200\n",
            "1/1 - 0s - loss: 0.5780 - accuracy: 0.8182 - 12ms/epoch - 12ms/step\n",
            "Epoch 114/200\n",
            "1/1 - 0s - loss: 0.5692 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "1/1 - 0s - loss: 0.5606 - accuracy: 0.8182 - 9ms/epoch - 9ms/step\n",
            "Epoch 116/200\n",
            "1/1 - 0s - loss: 0.5520 - accuracy: 0.8182 - 8ms/epoch - 8ms/step\n",
            "Epoch 117/200\n",
            "1/1 - 0s - loss: 0.5435 - accuracy: 0.8182 - 7ms/epoch - 7ms/step\n",
            "Epoch 118/200\n",
            "1/1 - 0s - loss: 0.5351 - accuracy: 0.8182 - 7ms/epoch - 7ms/step\n",
            "Epoch 119/200\n",
            "1/1 - 0s - loss: 0.5267 - accuracy: 0.8182 - 8ms/epoch - 8ms/step\n",
            "Epoch 120/200\n",
            "1/1 - 0s - loss: 0.5185 - accuracy: 0.8182 - 4ms/epoch - 4ms/step\n",
            "Epoch 121/200\n",
            "1/1 - 0s - loss: 0.5103 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
            "Epoch 122/200\n",
            "1/1 - 0s - loss: 0.5023 - accuracy: 0.8182 - 14ms/epoch - 14ms/step\n",
            "Epoch 123/200\n",
            "1/1 - 0s - loss: 0.4943 - accuracy: 0.8182 - 5ms/epoch - 5ms/step\n",
            "Epoch 124/200\n",
            "1/1 - 0s - loss: 0.4864 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
            "Epoch 125/200\n",
            "1/1 - 0s - loss: 0.4785 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
            "Epoch 126/200\n",
            "1/1 - 0s - loss: 0.4708 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
            "Epoch 127/200\n",
            "1/1 - 0s - loss: 0.4631 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 128/200\n",
            "1/1 - 0s - loss: 0.4555 - accuracy: 0.9091 - 10ms/epoch - 10ms/step\n",
            "Epoch 129/200\n",
            "1/1 - 0s - loss: 0.4479 - accuracy: 0.9091 - 8ms/epoch - 8ms/step\n",
            "Epoch 130/200\n",
            "1/1 - 0s - loss: 0.4405 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 131/200\n",
            "1/1 - 0s - loss: 0.4331 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 132/200\n",
            "1/1 - 0s - loss: 0.4258 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 133/200\n",
            "1/1 - 0s - loss: 0.4185 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 134/200\n",
            "1/1 - 0s - loss: 0.4114 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 135/200\n",
            "1/1 - 0s - loss: 0.4043 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 136/200\n",
            "1/1 - 0s - loss: 0.3973 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 137/200\n",
            "1/1 - 0s - loss: 0.3903 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 138/200\n",
            "1/1 - 0s - loss: 0.3835 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 139/200\n",
            "1/1 - 0s - loss: 0.3767 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 140/200\n",
            "1/1 - 0s - loss: 0.3700 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 141/200\n",
            "1/1 - 0s - loss: 0.3633 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 142/200\n",
            "1/1 - 0s - loss: 0.3567 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 143/200\n",
            "1/1 - 0s - loss: 0.3502 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 144/200\n",
            "1/1 - 0s - loss: 0.3438 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 145/200\n",
            "1/1 - 0s - loss: 0.3375 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 146/200\n",
            "1/1 - 0s - loss: 0.3312 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 147/200\n",
            "1/1 - 0s - loss: 0.3250 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 148/200\n",
            "1/1 - 0s - loss: 0.3189 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 149/200\n",
            "1/1 - 0s - loss: 0.3128 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 150/200\n",
            "1/1 - 0s - loss: 0.3069 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 151/200\n",
            "1/1 - 0s - loss: 0.3010 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 152/200\n",
            "1/1 - 0s - loss: 0.2952 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 153/200\n",
            "1/1 - 0s - loss: 0.2894 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 154/200\n",
            "1/1 - 0s - loss: 0.2838 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 155/200\n",
            "1/1 - 0s - loss: 0.2782 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 156/200\n",
            "1/1 - 0s - loss: 0.2727 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 157/200\n",
            "1/1 - 0s - loss: 0.2673 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 158/200\n",
            "1/1 - 0s - loss: 0.2619 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 159/200\n",
            "1/1 - 0s - loss: 0.2567 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 160/200\n",
            "1/1 - 0s - loss: 0.2515 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 161/200\n",
            "1/1 - 0s - loss: 0.2464 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 162/200\n",
            "1/1 - 0s - loss: 0.2413 - accuracy: 1.0000 - 3ms/epoch - 3ms/step\n",
            "Epoch 163/200\n",
            "1/1 - 0s - loss: 0.2364 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 164/200\n",
            "1/1 - 0s - loss: 0.2315 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 165/200\n",
            "1/1 - 0s - loss: 0.2268 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 166/200\n",
            "1/1 - 0s - loss: 0.2221 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 167/200\n",
            "1/1 - 0s - loss: 0.2174 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 168/200\n",
            "1/1 - 0s - loss: 0.2129 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 169/200\n",
            "1/1 - 0s - loss: 0.2085 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 170/200\n",
            "1/1 - 0s - loss: 0.2041 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 171/200\n",
            "1/1 - 0s - loss: 0.1998 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 172/200\n",
            "1/1 - 0s - loss: 0.1956 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 173/200\n",
            "1/1 - 0s - loss: 0.1915 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 174/200\n",
            "1/1 - 0s - loss: 0.1874 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 175/200\n",
            "1/1 - 0s - loss: 0.1835 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 176/200\n",
            "1/1 - 0s - loss: 0.1796 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 177/200\n",
            "1/1 - 0s - loss: 0.1758 - accuracy: 1.0000 - 11ms/epoch - 11ms/step\n",
            "Epoch 178/200\n",
            "1/1 - 0s - loss: 0.1721 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 179/200\n",
            "1/1 - 0s - loss: 0.1685 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 180/200\n",
            "1/1 - 0s - loss: 0.1649 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 181/200\n",
            "1/1 - 0s - loss: 0.1614 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 182/200\n",
            "1/1 - 0s - loss: 0.1581 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 183/200\n",
            "1/1 - 0s - loss: 0.1547 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 184/200\n",
            "1/1 - 0s - loss: 0.1515 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 185/200\n",
            "1/1 - 0s - loss: 0.1483 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 186/200\n",
            "1/1 - 0s - loss: 0.1452 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 187/200\n",
            "1/1 - 0s - loss: 0.1422 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 188/200\n",
            "1/1 - 0s - loss: 0.1393 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 189/200\n",
            "1/1 - 0s - loss: 0.1364 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 190/200\n",
            "1/1 - 0s - loss: 0.1336 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 191/200\n",
            "1/1 - 0s - loss: 0.1309 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 192/200\n",
            "1/1 - 0s - loss: 0.1282 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 193/200\n",
            "1/1 - 0s - loss: 0.1256 - accuracy: 1.0000 - 9ms/epoch - 9ms/step\n",
            "Epoch 194/200\n",
            "1/1 - 0s - loss: 0.1231 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n",
            "Epoch 195/200\n",
            "1/1 - 0s - loss: 0.1206 - accuracy: 1.0000 - 4ms/epoch - 4ms/step\n",
            "Epoch 196/200\n",
            "1/1 - 0s - loss: 0.1182 - accuracy: 1.0000 - 6ms/epoch - 6ms/step\n",
            "Epoch 197/200\n",
            "1/1 - 0s - loss: 0.1159 - accuracy: 1.0000 - 10ms/epoch - 10ms/step\n",
            "Epoch 198/200\n",
            "1/1 - 0s - loss: 0.1136 - accuracy: 1.0000 - 8ms/epoch - 8ms/step\n",
            "Epoch 199/200\n",
            "1/1 - 0s - loss: 0.1113 - accuracy: 1.0000 - 5ms/epoch - 5ms/step\n",
            "Epoch 200/200\n",
            "1/1 - 0s - loss: 0.1092 - accuracy: 1.0000 - 7ms/epoch - 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f94be201690>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델이 정확하게 예측하고 있는지 문장을 생성해주는 함수\n",
        "\n",
        "def sentence_generation(model,tokenizer,current_word,n):\n",
        "  init_word=current_word\n",
        "  sentence=''\n",
        "\n",
        "  #n번반복\n",
        "  for _ in range(n):\n",
        "    #현재 단어에 대한 정수 인코딩과 패딩\n",
        "    encoded=tokenizer.texts_to_sequences([current_word])[0]\n",
        "    encoded=pad_sequences([encoded],maxlen=5,padding='pre')\n",
        "    #입력한X에 대해서 Y를 예측하고 Y를 result에 저장.\n",
        "    result=model.predict(encoded,verbose=0)\n",
        "    result=np.argmax(result,axis=1)\n",
        "\n",
        "    for word,index in tokenizer.word_index.items():\n",
        "      #만약 예측한 단어와 인덱스와 동일한 단어가 있다면 break\n",
        "      if index==result:\n",
        "        break\n",
        "\n",
        "    # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "    current_word=current_word+' '+word\n",
        "\n",
        "    #예측단어를 문장에 저장\n",
        "    sentence=sentence+' '+word\n",
        "\n",
        "  sentence=init_word+sentence\n",
        "  return sentence\n"
      ],
      "metadata": {
        "id": "7t-7Nnbkqm5x"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '경마장에', 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG3xAlR1r4hO",
        "outputId": "178f49d2-c8d7-45ee-c902-45fc06cc9902"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "경마장에 있는 말이 뛰고 있다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '그의', 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JygLePU1r-iB",
        "outputId": "b32b4779-651e-4495-8a16-21b27286e8e7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "그의 말이 법이다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, '가는', 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vZy-GX2sAAI",
        "outputId": "2733bd9f-7df9-4040-ed91-b3a26768f711"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가는 말이 고와야 오는 말이 곱다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. LSTM으로 텍스트 생성"
      ],
      "metadata": {
        "id": "x1OHbQ_MsmH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['KAGGLE_USERNAME']='jiinpp'\n",
        "os.environ['KAGGLE_KEY']=\"b06d525a9f66198051ccb648b091778a\"\n",
        "\n",
        "!kaggle datasets download -d aashita/nyt-comments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNWU80X9sBRZ",
        "outputId": "5e1f9c72-0926-472c-e932-ba295bb8a16f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading nyt-comments.zip to /content\n",
            "100% 480M/480M [00:03<00:00, 110MB/s] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '*.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlihjUJvs34g",
        "outputId": "0c54a078-71bc-49ff-e756-c76b783ea63b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  nyt-comments.zip\n",
            "  inflating: ArticlesApril2017.csv   \n",
            "  inflating: ArticlesApril2018.csv   \n",
            "  inflating: ArticlesFeb2017.csv     \n",
            "  inflating: ArticlesFeb2018.csv     \n",
            "  inflating: ArticlesJan2017.csv     \n",
            "  inflating: ArticlesJan2018.csv     \n",
            "  inflating: ArticlesMarch2017.csv   \n",
            "  inflating: ArticlesMarch2018.csv   \n",
            "  inflating: ArticlesMay2017.csv     \n",
            "  inflating: CommentsApril2017.csv   \n",
            "  inflating: CommentsApril2018.csv   \n",
            "  inflating: CommentsFeb2017.csv     \n",
            "  inflating: CommentsFeb2018.csv     \n",
            "  inflating: CommentsJan2017.csv     \n",
            "  inflating: CommentsJan2018.csv     \n",
            "  inflating: CommentsMarch2017.csv   \n",
            "  inflating: CommentsMarch2018.csv   \n",
            "  inflating: CommentsMay2017.csv     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "QI3HwmmCs6WS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('ArticlesApril2018.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "2O_YarVvtlMr",
        "outputId": "c2087377-fa53-4d5c-bbd1-f2d2c6af7c62"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-74d312fe-0a82-4578-bb47-9c2dfb0862dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articleID</th>\n",
              "      <th>articleWordCount</th>\n",
              "      <th>byline</th>\n",
              "      <th>documentType</th>\n",
              "      <th>headline</th>\n",
              "      <th>keywords</th>\n",
              "      <th>multimedia</th>\n",
              "      <th>newDesk</th>\n",
              "      <th>printPage</th>\n",
              "      <th>pubDate</th>\n",
              "      <th>sectionName</th>\n",
              "      <th>snippet</th>\n",
              "      <th>source</th>\n",
              "      <th>typeOfMaterial</th>\n",
              "      <th>webURL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5adf6684068401528a2aa69b</td>\n",
              "      <td>781</td>\n",
              "      <td>By JOHN BRANCH</td>\n",
              "      <td>article</td>\n",
              "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
              "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
              "      <td>68</td>\n",
              "      <td>Sports</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:16:49</td>\n",
              "      <td>Pro Football</td>\n",
              "      <td>“I understand that they could meet with us, pa...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5adf653f068401528a2aa697</td>\n",
              "      <td>656</td>\n",
              "      <td>By LISA FRIEDMAN</td>\n",
              "      <td>article</td>\n",
              "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
              "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
              "      <td>68</td>\n",
              "      <td>Climate</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:11:21</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>The agency plans to publish a new regulation T...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5adf4626068401528a2aa628</td>\n",
              "      <td>2427</td>\n",
              "      <td>By PETE WELLS</td>\n",
              "      <td>article</td>\n",
              "      <td>The New Noma, Explained</td>\n",
              "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
              "      <td>66</td>\n",
              "      <td>Dining</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:58:44</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>What’s it like to eat at the second incarnatio...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5adf40d2068401528a2aa619</td>\n",
              "      <td>626</td>\n",
              "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
              "      <td>68</td>\n",
              "      <td>Washington</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:35:57</td>\n",
              "      <td>Europe</td>\n",
              "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5adf3d64068401528a2aa60f</td>\n",
              "      <td>815</td>\n",
              "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
              "      <td>68</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:21:21</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74d312fe-0a82-4578-bb47-9c2dfb0862dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74d312fe-0a82-4578-bb47-9c2dfb0862dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74d312fe-0a82-4578-bb47-9c2dfb0862dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  articleID  ...                                             webURL\n",
              "0  5adf6684068401528a2aa69b  ...  https://www.nytimes.com/2018/04/24/sports/foot...\n",
              "1  5adf653f068401528a2aa697  ...  https://www.nytimes.com/2018/04/24/climate/epa...\n",
              "2  5adf4626068401528a2aa628  ...  https://www.nytimes.com/2018/04/24/dining/noma...\n",
              "3  5adf40d2068401528a2aa619  ...  https://www.nytimes.com/2018/04/24/world/europ...\n",
              "4  5adf3d64068401528a2aa60f  ...  https://www.nytimes.com/2018/04/24/world/canad...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df.columns))\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzgxE747uOr_",
        "outputId": "2208857b-8149-4886-d823-d33193b22ad7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "Index(['articleID', 'articleWordCount', 'byline', 'documentType', 'headline',\n",
            "       'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n",
            "       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 사용할 열은 제목에 해당되는 headline열이다. NULL갑싱 있는지 확인해보자"
      ],
      "metadata": {
        "id": "85c44uMaucPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['headline'].isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIw1G0vkuUw_",
        "outputId": "8777e55d-a9d1-43b5-d6fa-e462e27d76b3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "headline열에서 모든 신문기사의 제목을 뽀아서 하나의 리스트로 저장해보자"
      ],
      "metadata": {
        "id": "w56HEdP_ukLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "headline=[]\n",
        "headline.extend(list(df.headline.values))\n",
        "headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AnTaIA8uaDX",
        "outputId": "4e1182a5-dd0d-474c-9999-8dfe3f1eabf5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
              " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
              " 'The New Noma, Explained',\n",
              " 'Unknown',\n",
              " 'Unknown']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "네번째와 다섯 번째 샘플에 Unknown 값이 들어가있습니다. headline 전체에 걸쳐서 Unknown 값을 가진 샘플이 있을 것으로 추정됩니다. 비록 Null 값은 아니지만 실습에 도움이 되지 않는 노이즈 데이터이므로 제거해줄 필요가 있습니다. 제거하기 전에 현재 샘플의 개수를 확인해보고 제거 전, 후의 샘플의 개수를 비교해봅시다."
      ],
      "metadata": {
        "id": "nu9wHdPAvKBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('총 샘플의 개수 : {}'.format(len(headline)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx5b3OOyvHcn",
        "outputId": "4d0bebb0-a091-4d5d-b25f-036450f0c83e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플의 개수 : 1324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headline=[word for word in headline if word!='Unknown']\n",
        "print('노이즈 값 제거 후 샘플의 개수 :{}'.format(len(headline)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaB8wGOBvLHi",
        "outputId": "3d156b31-2b33-4fd8-b713-eedc8c7636df"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "노이즈 값 제거 후 샘플의 개수 :1214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiZZTQWBvdpm",
        "outputId": "4e9296bf-f746-4ab2-9472-9d2140fc9e03"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
              " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
              " 'The New Noma, Explained',\n",
              " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
              " 'Is School a Place for Self-Expression?']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "구두점 제거, 단어의 소문자화"
      ],
      "metadata": {
        "id": "Mhso2t2Zv2Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def repreprocessing(raw_sentence):\n",
        "  preprocessed_sentence=raw_sentence.encode('utf8').decode('ascii','ignore')\n",
        "  #구두점 제거와 동시에 소문자화\n",
        "  return ''.join(word for word in preprocessed_sentence if word not in punctuation).lower()\n",
        "\n",
        "preprocessed_headline=[repreprocessing(x) for x in headline]\n",
        "preprocessed_headline[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKRwTeu4vgQ3",
        "outputId": "6fadd098-285d-4afd-ae9b-6cc8bd4ef1e6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
              " 'epa to unveil a new rule its effect less science in policymaking',\n",
              " 'the new noma explained',\n",
              " 'how a bag of texas dirt  became a times tradition',\n",
              " 'is school a place for selfexpression']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_headline)\n",
        "vocab_size=len(tokenizer.word_index)+1\n",
        "print('단어 집합의 크기 : %d'%vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykf4tAvhwVkv",
        "outputId": "24b75b90-906e-453a-fe4a-9966d913297a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 3494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences=list()\n",
        "\n",
        "for sentence in preprocessed_headline:\n",
        "\n",
        "  #각샘플에 대한 정수 인코딩\n",
        "  encoded=tokenizer.texts_to_sequences([sentence])[0]\n",
        "  for i in range(1,len(encoded)):\n",
        "    sequence=encoded[:i+1]\n",
        "    sequences.append(sequence)\n",
        "\n",
        "sequences[:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3EQZFzNxYkg",
        "outputId": "130ec63d-792e-4592-980d-e47832517359"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[99, 269],\n",
              " [99, 269, 371],\n",
              " [99, 269, 371, 1115],\n",
              " [99, 269, 371, 1115, 582],\n",
              " [99, 269, 371, 1115, 582, 52],\n",
              " [99, 269, 371, 1115, 582, 52, 7],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
              " [100, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "[[99, 269], # former nfl\n",
        " [99, 269, 371], # former nfl cheerleaders\n",
        " [99, 269, 371, 1115], # former nfl cheerleaders settlement\n",
        " [99, 269, 371, 1115, 582], # former nfl cheerleaders settlement offer\n",
        " [99, 269, 371, 1115, 582, 52], # 'former nfl cheerleaders settlement offer 1\n",
        " [99, 269, 371, 1115, 582, 52, 7], # former nfl cheerleaders settlement offer 1 and\n",
        " [99, 269, 371, 1115, 582, 52, 7, 2], # ... 이하 생략 ...\n",
        " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
        " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
        " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116], # 모든 단어가 사용된 완전한 첫번째 문장\n",
        " # 바로 위의 줄은 : former nfl cheerleaders settlement offer 1 and a meeting with goodell\n",
        " [100, 3]] # epa to에 해당되며 두번째 문장이 시작됨.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "LKuTkkxSyOgO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이해를 돕기 위해 출력 결과에 주석을 추가하였습니다. 왜 하나의 문장을 저렇게 나눌까요? 예를 들어 '경마장에 있는 말이 뛰고 있다' 라는 문장 하나가 있을 때, 최종적으로 원하는 훈련 데이터의 형태는 다음과 같습니다. 하나의 단어를 예측하기 위해 이전에 등장한 단어들을 모두 참고하는 것입니다."
      ],
      "metadata": {
        "id": "nuwIgk-XyLE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word={}\n",
        "for key,value in tokenizer.word_index.items():# 인덱스를 단어로 바꾸기 위해 index_to_word를 생성\n",
        "  index_to_word[value]=key\n",
        "\n",
        "print('빈도수 상위 582번 단어 : {}'.format(index_to_word[582]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B4YmFwcyFlC",
        "outputId": "267ba2b1-2cce-4b2e-bb36-905b115ffed3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "빈도수 상위 582번 단어 : offer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=max(len(l) for l in sequences)\n",
        "print('샘플의 최대 길이 : {}'.format(max_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TSeKQRBy1mW",
        "outputId": "896921ab-db5c-4283-fc8c-5a701c544af4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#패딩\n",
        "sequences=pad_sequences(sequences,maxlen=max_len,padding='pre')\n",
        "print(sequences[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVtCMQ_-zD1Q",
        "outputId": "b67455f3-a2ae-4628-f750-8567473ee892"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0   99  269]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0   99  269  371]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0   99  269  371 1115]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1]"
      ],
      "metadata": {
        "id": "oa8Sl0gNzLee"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjAgpFcyzhL_",
        "outputId": "a0df223f-9da1-491b-db72-aa76fb58e8e0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0  99]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0  99 269]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  99 269 371]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgsEf8vnziWh",
        "outputId": "fc6d95c9-cf7b-40ac-8cdf-2a93df421e47"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 269  371 1115]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=to_categorical(y,num_classes=vocab_size)#레이블데이터 y에 대해서 원핫인코딩"
      ],
      "metadata": {
        "id": "PRi1JsOozjdY"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 모델 설게"
      ],
      "metadata": {
        "id": "dYPumjeKz2Xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM"
      ],
      "metadata": {
        "id": "SBe6smuHz1dS"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼파라미터인 임베딩 벡터의 차원은 10, 은닉 상태의 크기는 128입니다. 다 대 일 구조의 LSTM을 사용합니다. 전결합층(Fully Connected Layer)을 출력층으로 단어 집합 크기만큼의 뉴런을 배치하여 모델을 설계합니다. 해당 모델은 마지막 시점에서 모든 가능한 단어 중 하나의 단어를 예측하는 다중 클래스 분류 문제를 수행하는 모델입니다. 다중 클래스 분류 문제의 경우, 출력층에 소프트맥스 회귀를 사용해야 하므로 활성화 함수로는 소프트맥스 함수를 사용하고, 손실 함수로 크로스 엔트로피 함수를 사용하여 200 에포크를 수행합니다."
      ],
      "metadata": {
        "id": "DOyGt5MI0RUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim=10\n",
        "hidden_units=128\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,embedding_dim))\n",
        "model.add(LSTM(hidden_units))\n",
        "model.add(Dense(vocab_size,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X,y,epochs=200,verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyrTWd-uz52W",
        "outputId": "cbaf6673-cc25-4a22-f7b8-9db15ec24c38"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "244/244 - 10s - loss: 7.6520 - accuracy: 0.0293 - 10s/epoch - 41ms/step\n",
            "Epoch 2/200\n",
            "244/244 - 8s - loss: 7.1195 - accuracy: 0.0282 - 8s/epoch - 31ms/step\n",
            "Epoch 3/200\n",
            "244/244 - 8s - loss: 6.9794 - accuracy: 0.0342 - 8s/epoch - 32ms/step\n",
            "Epoch 4/200\n",
            "244/244 - 8s - loss: 6.8549 - accuracy: 0.0410 - 8s/epoch - 32ms/step\n",
            "Epoch 5/200\n",
            "244/244 - 8s - loss: 6.7091 - accuracy: 0.0427 - 8s/epoch - 32ms/step\n",
            "Epoch 6/200\n",
            "244/244 - 8s - loss: 6.5427 - accuracy: 0.0486 - 8s/epoch - 32ms/step\n",
            "Epoch 7/200\n",
            "244/244 - 8s - loss: 6.3554 - accuracy: 0.0507 - 8s/epoch - 32ms/step\n",
            "Epoch 8/200\n",
            "244/244 - 8s - loss: 6.1592 - accuracy: 0.0564 - 8s/epoch - 32ms/step\n",
            "Epoch 9/200\n",
            "244/244 - 8s - loss: 5.9646 - accuracy: 0.0590 - 8s/epoch - 32ms/step\n",
            "Epoch 10/200\n",
            "244/244 - 8s - loss: 5.7697 - accuracy: 0.0648 - 8s/epoch - 32ms/step\n",
            "Epoch 11/200\n",
            "244/244 - 8s - loss: 5.5862 - accuracy: 0.0702 - 8s/epoch - 32ms/step\n",
            "Epoch 12/200\n",
            "244/244 - 8s - loss: 5.4132 - accuracy: 0.0727 - 8s/epoch - 32ms/step\n",
            "Epoch 13/200\n",
            "244/244 - 8s - loss: 5.2487 - accuracy: 0.0825 - 8s/epoch - 32ms/step\n",
            "Epoch 14/200\n",
            "244/244 - 8s - loss: 5.0935 - accuracy: 0.0854 - 8s/epoch - 32ms/step\n",
            "Epoch 15/200\n",
            "244/244 - 8s - loss: 4.9487 - accuracy: 0.0992 - 8s/epoch - 32ms/step\n",
            "Epoch 16/200\n",
            "244/244 - 8s - loss: 4.8070 - accuracy: 0.1091 - 8s/epoch - 32ms/step\n",
            "Epoch 17/200\n",
            "244/244 - 8s - loss: 4.6729 - accuracy: 0.1212 - 8s/epoch - 32ms/step\n",
            "Epoch 18/200\n",
            "244/244 - 8s - loss: 4.5431 - accuracy: 0.1348 - 8s/epoch - 32ms/step\n",
            "Epoch 19/200\n",
            "244/244 - 8s - loss: 4.4211 - accuracy: 0.1483 - 8s/epoch - 32ms/step\n",
            "Epoch 20/200\n",
            "244/244 - 8s - loss: 4.3017 - accuracy: 0.1649 - 8s/epoch - 32ms/step\n",
            "Epoch 21/200\n",
            "244/244 - 8s - loss: 4.1891 - accuracy: 0.1836 - 8s/epoch - 32ms/step\n",
            "Epoch 22/200\n",
            "244/244 - 8s - loss: 4.0759 - accuracy: 0.1954 - 8s/epoch - 32ms/step\n",
            "Epoch 23/200\n",
            "244/244 - 8s - loss: 3.9691 - accuracy: 0.2116 - 8s/epoch - 32ms/step\n",
            "Epoch 24/200\n",
            "244/244 - 8s - loss: 3.8646 - accuracy: 0.2332 - 8s/epoch - 32ms/step\n",
            "Epoch 25/200\n",
            "244/244 - 8s - loss: 3.7614 - accuracy: 0.2468 - 8s/epoch - 32ms/step\n",
            "Epoch 26/200\n",
            "244/244 - 8s - loss: 3.6662 - accuracy: 0.2671 - 8s/epoch - 32ms/step\n",
            "Epoch 27/200\n",
            "244/244 - 8s - loss: 3.5708 - accuracy: 0.2794 - 8s/epoch - 32ms/step\n",
            "Epoch 28/200\n",
            "244/244 - 8s - loss: 3.4824 - accuracy: 0.2945 - 8s/epoch - 32ms/step\n",
            "Epoch 29/200\n",
            "244/244 - 8s - loss: 3.3919 - accuracy: 0.3127 - 8s/epoch - 32ms/step\n",
            "Epoch 30/200\n",
            "244/244 - 8s - loss: 3.3075 - accuracy: 0.3300 - 8s/epoch - 32ms/step\n",
            "Epoch 31/200\n",
            "244/244 - 8s - loss: 3.2256 - accuracy: 0.3451 - 8s/epoch - 32ms/step\n",
            "Epoch 32/200\n",
            "244/244 - 8s - loss: 3.1428 - accuracy: 0.3629 - 8s/epoch - 32ms/step\n",
            "Epoch 33/200\n",
            "244/244 - 8s - loss: 3.0672 - accuracy: 0.3708 - 8s/epoch - 32ms/step\n",
            "Epoch 34/200\n",
            "244/244 - 8s - loss: 2.9920 - accuracy: 0.3882 - 8s/epoch - 32ms/step\n",
            "Epoch 35/200\n",
            "244/244 - 8s - loss: 2.9177 - accuracy: 0.3979 - 8s/epoch - 32ms/step\n",
            "Epoch 36/200\n",
            "244/244 - 8s - loss: 2.8504 - accuracy: 0.4160 - 8s/epoch - 32ms/step\n",
            "Epoch 37/200\n",
            "244/244 - 8s - loss: 2.7801 - accuracy: 0.4283 - 8s/epoch - 32ms/step\n",
            "Epoch 38/200\n",
            "244/244 - 8s - loss: 2.7153 - accuracy: 0.4439 - 8s/epoch - 32ms/step\n",
            "Epoch 39/200\n",
            "244/244 - 8s - loss: 2.6511 - accuracy: 0.4548 - 8s/epoch - 32ms/step\n",
            "Epoch 40/200\n",
            "244/244 - 8s - loss: 2.5893 - accuracy: 0.4633 - 8s/epoch - 32ms/step\n",
            "Epoch 41/200\n",
            "244/244 - 8s - loss: 2.5312 - accuracy: 0.4781 - 8s/epoch - 32ms/step\n",
            "Epoch 42/200\n",
            "244/244 - 8s - loss: 2.4710 - accuracy: 0.4893 - 8s/epoch - 32ms/step\n",
            "Epoch 43/200\n",
            "244/244 - 8s - loss: 2.4178 - accuracy: 0.5004 - 8s/epoch - 32ms/step\n",
            "Epoch 44/200\n",
            "244/244 - 8s - loss: 2.3637 - accuracy: 0.5084 - 8s/epoch - 32ms/step\n",
            "Epoch 45/200\n",
            "244/244 - 8s - loss: 2.3085 - accuracy: 0.5221 - 8s/epoch - 32ms/step\n",
            "Epoch 46/200\n",
            "244/244 - 8s - loss: 2.2548 - accuracy: 0.5316 - 8s/epoch - 32ms/step\n",
            "Epoch 47/200\n",
            "244/244 - 8s - loss: 2.2023 - accuracy: 0.5443 - 8s/epoch - 32ms/step\n",
            "Epoch 48/200\n",
            "244/244 - 8s - loss: 2.1532 - accuracy: 0.5579 - 8s/epoch - 32ms/step\n",
            "Epoch 49/200\n",
            "244/244 - 8s - loss: 2.1082 - accuracy: 0.5636 - 8s/epoch - 31ms/step\n",
            "Epoch 50/200\n",
            "244/244 - 8s - loss: 2.0574 - accuracy: 0.5744 - 8s/epoch - 32ms/step\n",
            "Epoch 51/200\n",
            "244/244 - 8s - loss: 2.0094 - accuracy: 0.5853 - 8s/epoch - 32ms/step\n",
            "Epoch 52/200\n",
            "244/244 - 8s - loss: 1.9670 - accuracy: 0.5940 - 8s/epoch - 32ms/step\n",
            "Epoch 53/200\n",
            "244/244 - 8s - loss: 1.9192 - accuracy: 0.6043 - 8s/epoch - 32ms/step\n",
            "Epoch 54/200\n",
            "244/244 - 8s - loss: 1.8769 - accuracy: 0.6112 - 8s/epoch - 32ms/step\n",
            "Epoch 55/200\n",
            "244/244 - 8s - loss: 1.8326 - accuracy: 0.6242 - 8s/epoch - 32ms/step\n",
            "Epoch 56/200\n",
            "244/244 - 8s - loss: 1.7936 - accuracy: 0.6324 - 8s/epoch - 32ms/step\n",
            "Epoch 57/200\n",
            "244/244 - 8s - loss: 1.7492 - accuracy: 0.6419 - 8s/epoch - 32ms/step\n",
            "Epoch 58/200\n",
            "244/244 - 8s - loss: 1.7103 - accuracy: 0.6496 - 8s/epoch - 32ms/step\n",
            "Epoch 59/200\n",
            "244/244 - 8s - loss: 1.6704 - accuracy: 0.6622 - 8s/epoch - 32ms/step\n",
            "Epoch 60/200\n",
            "244/244 - 8s - loss: 1.6328 - accuracy: 0.6735 - 8s/epoch - 32ms/step\n",
            "Epoch 61/200\n",
            "244/244 - 8s - loss: 1.5920 - accuracy: 0.6790 - 8s/epoch - 32ms/step\n",
            "Epoch 62/200\n",
            "244/244 - 8s - loss: 1.5550 - accuracy: 0.6844 - 8s/epoch - 32ms/step\n",
            "Epoch 63/200\n",
            "244/244 - 8s - loss: 1.5167 - accuracy: 0.6999 - 8s/epoch - 32ms/step\n",
            "Epoch 64/200\n",
            "244/244 - 8s - loss: 1.4831 - accuracy: 0.7027 - 8s/epoch - 32ms/step\n",
            "Epoch 65/200\n",
            "244/244 - 8s - loss: 1.4479 - accuracy: 0.7102 - 8s/epoch - 32ms/step\n",
            "Epoch 66/200\n",
            "244/244 - 8s - loss: 1.4158 - accuracy: 0.7200 - 8s/epoch - 32ms/step\n",
            "Epoch 67/200\n",
            "244/244 - 8s - loss: 1.3859 - accuracy: 0.7246 - 8s/epoch - 32ms/step\n",
            "Epoch 68/200\n",
            "244/244 - 8s - loss: 1.3549 - accuracy: 0.7342 - 8s/epoch - 32ms/step\n",
            "Epoch 69/200\n",
            "244/244 - 8s - loss: 1.3169 - accuracy: 0.7429 - 8s/epoch - 32ms/step\n",
            "Epoch 70/200\n",
            "244/244 - 8s - loss: 1.2865 - accuracy: 0.7471 - 8s/epoch - 32ms/step\n",
            "Epoch 71/200\n",
            "244/244 - 8s - loss: 1.2551 - accuracy: 0.7514 - 8s/epoch - 32ms/step\n",
            "Epoch 72/200\n",
            "244/244 - 8s - loss: 1.2229 - accuracy: 0.7611 - 8s/epoch - 31ms/step\n",
            "Epoch 73/200\n",
            "244/244 - 8s - loss: 1.1963 - accuracy: 0.7682 - 8s/epoch - 32ms/step\n",
            "Epoch 74/200\n",
            "244/244 - 8s - loss: 1.1658 - accuracy: 0.7743 - 8s/epoch - 32ms/step\n",
            "Epoch 75/200\n",
            "244/244 - 8s - loss: 1.1406 - accuracy: 0.7782 - 8s/epoch - 32ms/step\n",
            "Epoch 76/200\n",
            "244/244 - 8s - loss: 1.1117 - accuracy: 0.7833 - 8s/epoch - 32ms/step\n",
            "Epoch 77/200\n",
            "244/244 - 8s - loss: 1.0836 - accuracy: 0.7884 - 8s/epoch - 32ms/step\n",
            "Epoch 78/200\n",
            "244/244 - 8s - loss: 1.0575 - accuracy: 0.7942 - 8s/epoch - 32ms/step\n",
            "Epoch 79/200\n",
            "244/244 - 8s - loss: 1.0321 - accuracy: 0.8006 - 8s/epoch - 32ms/step\n",
            "Epoch 80/200\n",
            "244/244 - 8s - loss: 1.0068 - accuracy: 0.8067 - 8s/epoch - 31ms/step\n",
            "Epoch 81/200\n",
            "244/244 - 8s - loss: 0.9849 - accuracy: 0.8080 - 8s/epoch - 32ms/step\n",
            "Epoch 82/200\n",
            "244/244 - 8s - loss: 0.9606 - accuracy: 0.8149 - 8s/epoch - 32ms/step\n",
            "Epoch 83/200\n",
            "244/244 - 8s - loss: 0.9376 - accuracy: 0.8190 - 8s/epoch - 32ms/step\n",
            "Epoch 84/200\n",
            "244/244 - 8s - loss: 0.9108 - accuracy: 0.8261 - 8s/epoch - 32ms/step\n",
            "Epoch 85/200\n",
            "244/244 - 8s - loss: 0.8913 - accuracy: 0.8297 - 8s/epoch - 32ms/step\n",
            "Epoch 86/200\n",
            "244/244 - 8s - loss: 0.8684 - accuracy: 0.8329 - 8s/epoch - 32ms/step\n",
            "Epoch 87/200\n",
            "244/244 - 8s - loss: 0.8492 - accuracy: 0.8370 - 8s/epoch - 32ms/step\n",
            "Epoch 88/200\n",
            "244/244 - 8s - loss: 0.8262 - accuracy: 0.8389 - 8s/epoch - 31ms/step\n",
            "Epoch 89/200\n",
            "244/244 - 8s - loss: 0.8061 - accuracy: 0.8451 - 8s/epoch - 32ms/step\n",
            "Epoch 90/200\n",
            "244/244 - 8s - loss: 0.7869 - accuracy: 0.8447 - 8s/epoch - 32ms/step\n",
            "Epoch 91/200\n",
            "244/244 - 8s - loss: 0.7679 - accuracy: 0.8515 - 8s/epoch - 32ms/step\n",
            "Epoch 92/200\n",
            "244/244 - 8s - loss: 0.7560 - accuracy: 0.8507 - 8s/epoch - 32ms/step\n",
            "Epoch 93/200\n",
            "244/244 - 8s - loss: 0.7306 - accuracy: 0.8551 - 8s/epoch - 32ms/step\n",
            "Epoch 94/200\n",
            "244/244 - 8s - loss: 0.7156 - accuracy: 0.8604 - 8s/epoch - 32ms/step\n",
            "Epoch 95/200\n",
            "244/244 - 8s - loss: 0.6968 - accuracy: 0.8624 - 8s/epoch - 32ms/step\n",
            "Epoch 96/200\n",
            "244/244 - 8s - loss: 0.6817 - accuracy: 0.8652 - 8s/epoch - 32ms/step\n",
            "Epoch 97/200\n",
            "244/244 - 8s - loss: 0.6708 - accuracy: 0.8674 - 8s/epoch - 32ms/step\n",
            "Epoch 98/200\n",
            "244/244 - 8s - loss: 0.6587 - accuracy: 0.8683 - 8s/epoch - 32ms/step\n",
            "Epoch 99/200\n",
            "244/244 - 8s - loss: 0.6378 - accuracy: 0.8749 - 8s/epoch - 33ms/step\n",
            "Epoch 100/200\n",
            "244/244 - 8s - loss: 0.6214 - accuracy: 0.8777 - 8s/epoch - 33ms/step\n",
            "Epoch 101/200\n",
            "244/244 - 8s - loss: 0.6118 - accuracy: 0.8786 - 8s/epoch - 32ms/step\n",
            "Epoch 102/200\n",
            "244/244 - 8s - loss: 0.5987 - accuracy: 0.8804 - 8s/epoch - 32ms/step\n",
            "Epoch 103/200\n",
            "244/244 - 8s - loss: 0.5881 - accuracy: 0.8816 - 8s/epoch - 32ms/step\n",
            "Epoch 104/200\n",
            "244/244 - 8s - loss: 0.5722 - accuracy: 0.8852 - 8s/epoch - 32ms/step\n",
            "Epoch 105/200\n",
            "244/244 - 8s - loss: 0.5567 - accuracy: 0.8876 - 8s/epoch - 33ms/step\n",
            "Epoch 106/200\n",
            "244/244 - 8s - loss: 0.5460 - accuracy: 0.8882 - 8s/epoch - 32ms/step\n",
            "Epoch 107/200\n",
            "244/244 - 8s - loss: 0.5368 - accuracy: 0.8930 - 8s/epoch - 32ms/step\n",
            "Epoch 108/200\n",
            "244/244 - 8s - loss: 0.5241 - accuracy: 0.8947 - 8s/epoch - 32ms/step\n",
            "Epoch 109/200\n",
            "244/244 - 8s - loss: 0.5161 - accuracy: 0.8967 - 8s/epoch - 32ms/step\n",
            "Epoch 110/200\n",
            "244/244 - 8s - loss: 0.5039 - accuracy: 0.8973 - 8s/epoch - 32ms/step\n",
            "Epoch 111/200\n",
            "244/244 - 8s - loss: 0.4930 - accuracy: 0.8991 - 8s/epoch - 32ms/step\n",
            "Epoch 112/200\n",
            "244/244 - 8s - loss: 0.4855 - accuracy: 0.8998 - 8s/epoch - 32ms/step\n",
            "Epoch 113/200\n",
            "244/244 - 8s - loss: 0.4735 - accuracy: 0.9040 - 8s/epoch - 32ms/step\n",
            "Epoch 114/200\n",
            "244/244 - 8s - loss: 0.4668 - accuracy: 0.9044 - 8s/epoch - 32ms/step\n",
            "Epoch 115/200\n",
            "244/244 - 8s - loss: 0.4667 - accuracy: 0.9031 - 8s/epoch - 32ms/step\n",
            "Epoch 116/200\n",
            "244/244 - 8s - loss: 0.4647 - accuracy: 0.9035 - 8s/epoch - 32ms/step\n",
            "Epoch 117/200\n",
            "244/244 - 8s - loss: 0.4473 - accuracy: 0.9067 - 8s/epoch - 32ms/step\n",
            "Epoch 118/200\n",
            "244/244 - 8s - loss: 0.4349 - accuracy: 0.9102 - 8s/epoch - 32ms/step\n",
            "Epoch 119/200\n",
            "244/244 - 8s - loss: 0.4252 - accuracy: 0.9095 - 8s/epoch - 32ms/step\n",
            "Epoch 120/200\n",
            "244/244 - 8s - loss: 0.4173 - accuracy: 0.9097 - 8s/epoch - 32ms/step\n",
            "Epoch 121/200\n",
            "244/244 - 8s - loss: 0.4129 - accuracy: 0.9107 - 8s/epoch - 32ms/step\n",
            "Epoch 122/200\n",
            "244/244 - 8s - loss: 0.4051 - accuracy: 0.9112 - 8s/epoch - 32ms/step\n",
            "Epoch 123/200\n",
            "244/244 - 8s - loss: 0.3989 - accuracy: 0.9116 - 8s/epoch - 32ms/step\n",
            "Epoch 124/200\n",
            "244/244 - 8s - loss: 0.3939 - accuracy: 0.9112 - 8s/epoch - 32ms/step\n",
            "Epoch 125/200\n",
            "244/244 - 8s - loss: 0.3866 - accuracy: 0.9134 - 8s/epoch - 32ms/step\n",
            "Epoch 126/200\n",
            "244/244 - 8s - loss: 0.3848 - accuracy: 0.9139 - 8s/epoch - 32ms/step\n",
            "Epoch 127/200\n",
            "244/244 - 8s - loss: 0.3852 - accuracy: 0.9136 - 8s/epoch - 32ms/step\n",
            "Epoch 128/200\n",
            "244/244 - 8s - loss: 0.3767 - accuracy: 0.9145 - 8s/epoch - 32ms/step\n",
            "Epoch 129/200\n",
            "244/244 - 8s - loss: 0.3683 - accuracy: 0.9153 - 8s/epoch - 32ms/step\n",
            "Epoch 130/200\n",
            "244/244 - 8s - loss: 0.3616 - accuracy: 0.9153 - 8s/epoch - 32ms/step\n",
            "Epoch 131/200\n",
            "244/244 - 8s - loss: 0.3571 - accuracy: 0.9155 - 8s/epoch - 32ms/step\n",
            "Epoch 132/200\n",
            "244/244 - 8s - loss: 0.3524 - accuracy: 0.9163 - 8s/epoch - 32ms/step\n",
            "Epoch 133/200\n",
            "244/244 - 8s - loss: 0.3542 - accuracy: 0.9140 - 8s/epoch - 32ms/step\n",
            "Epoch 134/200\n",
            "244/244 - 8s - loss: 0.3582 - accuracy: 0.9144 - 8s/epoch - 32ms/step\n",
            "Epoch 135/200\n",
            "244/244 - 8s - loss: 0.3504 - accuracy: 0.9125 - 8s/epoch - 32ms/step\n",
            "Epoch 136/200\n",
            "244/244 - 8s - loss: 0.3410 - accuracy: 0.9157 - 8s/epoch - 32ms/step\n",
            "Epoch 137/200\n",
            "244/244 - 8s - loss: 0.3355 - accuracy: 0.9171 - 8s/epoch - 32ms/step\n",
            "Epoch 138/200\n",
            "244/244 - 8s - loss: 0.3305 - accuracy: 0.9163 - 8s/epoch - 32ms/step\n",
            "Epoch 139/200\n",
            "244/244 - 8s - loss: 0.3255 - accuracy: 0.9175 - 8s/epoch - 32ms/step\n",
            "Epoch 140/200\n",
            "244/244 - 8s - loss: 0.3221 - accuracy: 0.9171 - 8s/epoch - 32ms/step\n",
            "Epoch 141/200\n",
            "244/244 - 8s - loss: 0.3214 - accuracy: 0.9164 - 8s/epoch - 32ms/step\n",
            "Epoch 142/200\n",
            "244/244 - 8s - loss: 0.3200 - accuracy: 0.9164 - 8s/epoch - 32ms/step\n",
            "Epoch 143/200\n",
            "244/244 - 8s - loss: 0.3162 - accuracy: 0.9164 - 8s/epoch - 32ms/step\n",
            "Epoch 144/200\n",
            "244/244 - 8s - loss: 0.3156 - accuracy: 0.9163 - 8s/epoch - 32ms/step\n",
            "Epoch 145/200\n",
            "244/244 - 8s - loss: 0.3375 - accuracy: 0.9111 - 8s/epoch - 32ms/step\n",
            "Epoch 146/200\n",
            "244/244 - 8s - loss: 0.3829 - accuracy: 0.9023 - 8s/epoch - 32ms/step\n",
            "Epoch 147/200\n",
            "244/244 - 8s - loss: 0.3224 - accuracy: 0.9153 - 8s/epoch - 32ms/step\n",
            "Epoch 148/200\n",
            "244/244 - 8s - loss: 0.3076 - accuracy: 0.9155 - 8s/epoch - 31ms/step\n",
            "Epoch 149/200\n",
            "244/244 - 8s - loss: 0.3031 - accuracy: 0.9172 - 8s/epoch - 32ms/step\n",
            "Epoch 150/200\n",
            "244/244 - 8s - loss: 0.3018 - accuracy: 0.9166 - 8s/epoch - 32ms/step\n",
            "Epoch 151/200\n",
            "244/244 - 8s - loss: 0.2989 - accuracy: 0.9189 - 8s/epoch - 32ms/step\n",
            "Epoch 152/200\n",
            "244/244 - 8s - loss: 0.2987 - accuracy: 0.9162 - 8s/epoch - 32ms/step\n",
            "Epoch 153/200\n",
            "244/244 - 8s - loss: 0.2970 - accuracy: 0.9145 - 8s/epoch - 32ms/step\n",
            "Epoch 154/200\n",
            "244/244 - 8s - loss: 0.2957 - accuracy: 0.9150 - 8s/epoch - 32ms/step\n",
            "Epoch 155/200\n",
            "244/244 - 8s - loss: 0.2944 - accuracy: 0.9162 - 8s/epoch - 32ms/step\n",
            "Epoch 156/200\n",
            "244/244 - 8s - loss: 0.2934 - accuracy: 0.9162 - 8s/epoch - 31ms/step\n",
            "Epoch 157/200\n",
            "244/244 - 8s - loss: 0.2912 - accuracy: 0.9168 - 8s/epoch - 32ms/step\n",
            "Epoch 158/200\n",
            "244/244 - 8s - loss: 0.2907 - accuracy: 0.9159 - 8s/epoch - 32ms/step\n",
            "Epoch 159/200\n",
            "244/244 - 8s - loss: 0.2910 - accuracy: 0.9171 - 8s/epoch - 32ms/step\n",
            "Epoch 160/200\n",
            "244/244 - 8s - loss: 0.3149 - accuracy: 0.9139 - 8s/epoch - 32ms/step\n",
            "Epoch 161/200\n",
            "244/244 - 8s - loss: 0.3219 - accuracy: 0.9113 - 8s/epoch - 32ms/step\n",
            "Epoch 162/200\n",
            "244/244 - 8s - loss: 0.2956 - accuracy: 0.9149 - 8s/epoch - 32ms/step\n",
            "Epoch 163/200\n",
            "244/244 - 8s - loss: 0.2854 - accuracy: 0.9162 - 8s/epoch - 32ms/step\n",
            "Epoch 164/200\n",
            "244/244 - 8s - loss: 0.2839 - accuracy: 0.9181 - 8s/epoch - 33ms/step\n",
            "Epoch 165/200\n",
            "244/244 - 8s - loss: 0.2819 - accuracy: 0.9171 - 8s/epoch - 32ms/step\n",
            "Epoch 166/200\n",
            "244/244 - 8s - loss: 0.2814 - accuracy: 0.9164 - 8s/epoch - 32ms/step\n",
            "Epoch 167/200\n",
            "244/244 - 8s - loss: 0.2798 - accuracy: 0.9175 - 8s/epoch - 32ms/step\n",
            "Epoch 168/200\n",
            "244/244 - 8s - loss: 0.2800 - accuracy: 0.9181 - 8s/epoch - 32ms/step\n",
            "Epoch 169/200\n",
            "244/244 - 8s - loss: 0.2793 - accuracy: 0.9159 - 8s/epoch - 32ms/step\n",
            "Epoch 170/200\n",
            "244/244 - 8s - loss: 0.2787 - accuracy: 0.9168 - 8s/epoch - 32ms/step\n",
            "Epoch 171/200\n",
            "244/244 - 8s - loss: 0.2786 - accuracy: 0.9168 - 8s/epoch - 32ms/step\n",
            "Epoch 172/200\n",
            "244/244 - 8s - loss: 0.2852 - accuracy: 0.9161 - 8s/epoch - 32ms/step\n",
            "Epoch 173/200\n",
            "244/244 - 8s - loss: 0.2885 - accuracy: 0.9158 - 8s/epoch - 32ms/step\n",
            "Epoch 174/200\n",
            "244/244 - 8s - loss: 0.2814 - accuracy: 0.9168 - 8s/epoch - 32ms/step\n",
            "Epoch 175/200\n",
            "244/244 - 8s - loss: 0.2782 - accuracy: 0.9158 - 8s/epoch - 32ms/step\n",
            "Epoch 176/200\n",
            "244/244 - 8s - loss: 0.2743 - accuracy: 0.9179 - 8s/epoch - 32ms/step\n",
            "Epoch 177/200\n",
            "244/244 - 8s - loss: 0.2737 - accuracy: 0.9179 - 8s/epoch - 32ms/step\n",
            "Epoch 178/200\n",
            "244/244 - 8s - loss: 0.2735 - accuracy: 0.9148 - 8s/epoch - 32ms/step\n",
            "Epoch 179/200\n",
            "244/244 - 8s - loss: 0.2729 - accuracy: 0.9154 - 8s/epoch - 32ms/step\n",
            "Epoch 180/200\n",
            "244/244 - 8s - loss: 0.2717 - accuracy: 0.9179 - 8s/epoch - 32ms/step\n",
            "Epoch 181/200\n",
            "244/244 - 8s - loss: 0.2714 - accuracy: 0.9168 - 8s/epoch - 32ms/step\n",
            "Epoch 182/200\n",
            "244/244 - 8s - loss: 0.2705 - accuracy: 0.9157 - 8s/epoch - 32ms/step\n",
            "Epoch 183/200\n",
            "244/244 - 8s - loss: 0.2703 - accuracy: 0.9170 - 8s/epoch - 32ms/step\n",
            "Epoch 184/200\n",
            "244/244 - 8s - loss: 0.2703 - accuracy: 0.9162 - 8s/epoch - 32ms/step\n",
            "Epoch 185/200\n",
            "244/244 - 8s - loss: 0.2700 - accuracy: 0.9164 - 8s/epoch - 32ms/step\n",
            "Epoch 186/200\n",
            "244/244 - 8s - loss: 0.2703 - accuracy: 0.9159 - 8s/epoch - 32ms/step\n",
            "Epoch 187/200\n",
            "244/244 - 8s - loss: 0.3096 - accuracy: 0.9112 - 8s/epoch - 32ms/step\n",
            "Epoch 188/200\n",
            "244/244 - 8s - loss: 0.3172 - accuracy: 0.9071 - 8s/epoch - 31ms/step\n",
            "Epoch 189/200\n",
            "244/244 - 8s - loss: 0.2752 - accuracy: 0.9163 - 8s/epoch - 32ms/step\n",
            "Epoch 190/200\n",
            "244/244 - 8s - loss: 0.2684 - accuracy: 0.9177 - 8s/epoch - 32ms/step\n",
            "Epoch 191/200\n",
            "244/244 - 8s - loss: 0.2669 - accuracy: 0.9158 - 8s/epoch - 32ms/step\n",
            "Epoch 192/200\n",
            "244/244 - 8s - loss: 0.2649 - accuracy: 0.9172 - 8s/epoch - 32ms/step\n",
            "Epoch 193/200\n",
            "244/244 - 8s - loss: 0.2659 - accuracy: 0.9150 - 8s/epoch - 32ms/step\n",
            "Epoch 194/200\n",
            "244/244 - 8s - loss: 0.2649 - accuracy: 0.9167 - 8s/epoch - 31ms/step\n",
            "Epoch 195/200\n",
            "244/244 - 8s - loss: 0.2638 - accuracy: 0.9171 - 8s/epoch - 31ms/step\n",
            "Epoch 196/200\n",
            "244/244 - 8s - loss: 0.2647 - accuracy: 0.9161 - 8s/epoch - 32ms/step\n",
            "Epoch 197/200\n",
            "244/244 - 8s - loss: 0.2648 - accuracy: 0.9164 - 8s/epoch - 32ms/step\n",
            "Epoch 198/200\n",
            "244/244 - 8s - loss: 0.2649 - accuracy: 0.9161 - 8s/epoch - 32ms/step\n",
            "Epoch 199/200\n",
            "244/244 - 8s - loss: 0.2653 - accuracy: 0.9157 - 8s/epoch - 32ms/step\n",
            "Epoch 200/200\n",
            "244/244 - 8s - loss: 0.2635 - accuracy: 0.9164 - 8s/epoch - 32ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f94bb6959d0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "    init_word = current_word\n",
        "    sentence = ''\n",
        "\n",
        "    # n번 반복\n",
        "    for _ in range(n):\n",
        "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre')\n",
        "\n",
        "        # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
        "        result = model.predict(encoded, verbose=0)\n",
        "        result = np.argmax(result, axis=1)\n",
        "\n",
        "        for word, index in tokenizer.word_index.items(): \n",
        "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
        "            if index == result:\n",
        "                break\n",
        "\n",
        "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "        current_word = current_word + ' '  + word\n",
        "\n",
        "        # 예측 단어를 문장에 저장\n",
        "        sentence = sentence + ' ' + word\n",
        "\n",
        "    sentence = init_word + sentence\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "RW35alIk1FiF"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, 'i', 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bmb3H5UEXiP",
        "outputId": "26ed7a7b-f27f-4bae-b0ec-25c36e49a474"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i want to be rich and im not sorry moves to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_generation(model, tokenizer, 'how', 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yWNoKj_EbSW",
        "outputId": "3d231c86-a79b-4009-ecb5-f312389f79c7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how to make facebook more accountable can the russia investigation may\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TQ3ahGUmEd3p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}